{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (2.15.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.26.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (69.0.3)\n",
      "Requirement already satisfied: six>1.9 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Google Colab. Assuming local environment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the notebook is running on Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # This block will run only in Google Colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab. Cloning the repository.\")\n",
    "    !git clone https://github.com/pedro15sousa/R244-wm-load-balancing.git\n",
    "    %cd R244-wm-load-balancing/notebooks\n",
    "else: \n",
    "    # This block will run if not in Google Colab\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab. Assuming local environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # This adds the parent directory (main_folder) to the Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Recurrent model training (memory)\"\"\"\n",
    "import argparse\n",
    "from functools import partial\n",
    "from os.path import join, exists\n",
    "from os import mkdir\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.misc import save_checkpoint\n",
    "from utils.misc import ASIZE, LSIZE, RSIZE, RED_SIZE, SIZE\n",
    "from utils.learning import EarlyStopping\n",
    "## WARNING : THIS SHOULD BE REPLACED WITH PYTORCH 0.5\n",
    "from utils.learning import ReduceLROnPlateau\n",
    "\n",
    "from data.loaders import RolloutSequenceDataset\n",
    "from models.vae import VAE\n",
    "from models.mdrnn import MDRNN, gmm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(\"MDRNN training\")\n",
    "# parser.add_argument('--logdir', type=str,\n",
    "#                     help=\"Where things are logged and models are loaded from.\")\n",
    "# parser.add_argument('--epochs', type=int, default=60, metavar='N',\n",
    "#                     help='number of epochs to train (default: 1000)')\n",
    "# parser.add_argument('--noreload', action='store_true',\n",
    "#                     help=\"Do not reload if specified.\")\n",
    "# parser.add_argument('--include_reward', action='store_true',\n",
    "#                     help=\"Add a reward modelisation term to the loss.\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "args = {\n",
    "    'batch_size': 32,   # input batch size for training (default: 32)\n",
    "    'epochs': 4000,     # number of epochs to train (default: 1000)\n",
    "    'logdir': '../exp_dir',  # Directory where results are logged\n",
    "    'include_reward': False,  # Set True if best model is not to be reloaded\n",
    "    'noreload': False,  # Set True if samples are not to be saved during training\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vae():\n",
    "    # Loading VAE\n",
    "    vae_file = join(args.logdir, 'vae', 'best.tar')\n",
    "    assert exists(vae_file), \"No trained VAE in the logdir...\"\n",
    "    state = torch.load(vae_file)\n",
    "    print(\"Loading VAE at epoch {} \"\n",
    "        \"with test error {}\".format(\n",
    "            state['epoch'], state['precision']))\n",
    "\n",
    "    vae = VAE(ASIZE+1, LSIZE).to(device)\n",
    "    vae.load_state_dict(state['state_dict'])\n",
    "    return vae, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset_train = RolloutSequenceDataset('../datasets/loadbalancing', SEQ_LEN, train=True, buffer_size=30)\n",
    "    dataset_test = RolloutSequenceDataset('../datasets/loadbalancing', SEQ_LEN, train=False, buffer_size=30)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset_train, batch_size=BSIZE, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(\n",
    "        dataset_test, batch_size=BSIZE, num_workers=2)\n",
    "\n",
    "    return dataset_test, dataset_train, test_loader, train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_action(action):\n",
    "    # Create a zero tensor for one-hot encoding\n",
    "    one_hot_actions = torch.zeros(SEQ_LEN, BSIZE, ASIZE)\n",
    "    # Fill with ones at the corresponding indices\n",
    "    for i in range(action.size(0)):\n",
    "        for j in range(action.size(1)):\n",
    "            action_index = action[i, j].long()  # convert to long for indexing\n",
    "            one_hot_actions[i, j, action_index] = 1\n",
    "    return one_hot_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(obs, action, reward, terminal,\n",
    "             next_obs, include_reward: bool):\n",
    "    \"\"\" Compute losses.\n",
    "\n",
    "    The loss that is computed is:\n",
    "    (GMMLoss(latent_next_obs, GMMPredicted) + MSE(reward, predicted_reward) +\n",
    "         BCE(terminal, logit_terminal)) / (LSIZE + 2)\n",
    "    The LSIZE + 2 factor is here to counteract the fact that the GMMLoss scales\n",
    "    approximately linearily with LSIZE. All losses are averaged both on the\n",
    "    batch and the sequence dimensions (the two first dimensions).\n",
    "\n",
    "    :args latent_obs: (BSIZE, SEQ_LEN, LSIZE) torch tensor\n",
    "    :args action: (BSIZE, SEQ_LEN, ASIZE) torch tensor\n",
    "    :args reward: (BSIZE, SEQ_LEN) torch tensor\n",
    "    :args latent_next_obs: (BSIZE, SEQ_LEN, LSIZE) torch tensor\n",
    "\n",
    "    :returns: dictionary of losses, containing the gmm, the mse, the bce and\n",
    "        the averaged loss.\n",
    "    \"\"\"\n",
    "    obs, action,\\\n",
    "        reward, terminal,\\\n",
    "        next_obs = [arr.transpose(1, 0)\n",
    "                           for arr in [obs, action,\n",
    "                                       reward, terminal,\n",
    "                                       next_obs]]\n",
    "    \n",
    "    # print(\"\\n--------------------\")\n",
    "    # print(\"action shape: \", action.shape)\n",
    "    # print(\"obs shape: \", obs.shape)\n",
    "    # print(\"reward shape: \", reward.shape)\n",
    "    # print(\"next_obs shape: \", next_obs.shape)\n",
    "    action = process_action(action)\n",
    "    # print(\"action shape: \", action.shape)\n",
    "    mus, sigmas, logpi, rs, ds = mdrnn(action, obs)\n",
    "    gmm = gmm_loss(next_obs, mus, sigmas, logpi)\n",
    "    bce = f.binary_cross_entropy_with_logits(ds, terminal)\n",
    "    if include_reward:\n",
    "        mse = f.mse_loss(rs, reward)\n",
    "        scale = LSIZE + 2\n",
    "    else:\n",
    "        mse = 0\n",
    "        scale = LSIZE + 1\n",
    "    loss = (gmm + bce + mse) / scale\n",
    "    return dict(gmm=gmm, bce=bce, mse=mse, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pass(epoch, train, include_reward): # pylint: disable=too-many-locals\n",
    "    \"\"\" One pass through the data \"\"\"\n",
    "    if train:\n",
    "        mdrnn.train()\n",
    "        loader = train_loader\n",
    "    else:\n",
    "        mdrnn.eval()\n",
    "        loader = test_loader\n",
    "\n",
    "    loader.dataset.load_next_buffer()\n",
    "\n",
    "    cum_loss = 0\n",
    "    cum_gmm = 0\n",
    "    cum_bce = 0\n",
    "    cum_mse = 0\n",
    "\n",
    "    pbar = tqdm(total=len(loader.dataset), desc=\"Epoch {}\".format(epoch))\n",
    "    for i, data in enumerate(loader):\n",
    "        obs, action, reward, terminal, next_obs = [arr.float().to(device) for arr in data]\n",
    "\n",
    "        if train:\n",
    "            losses = get_loss(obs, action, reward,\n",
    "                              terminal, next_obs, include_reward)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses['loss'].backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                losses = get_loss(obs, action, reward,\n",
    "                                  terminal, next_obs, include_reward)\n",
    "\n",
    "        cum_loss += losses['loss'].item()\n",
    "        cum_gmm += losses['gmm'].item()\n",
    "        cum_bce += losses['bce'].item()\n",
    "        cum_mse += losses['mse'].item() if hasattr(losses['mse'], 'item') else \\\n",
    "            losses['mse']\n",
    "\n",
    "        pbar.set_postfix_str(\"loss={loss:10.6f} bce={bce:10.6f} \"\n",
    "                             \"gmm={gmm:10.6f} mse={mse:10.6f}\".format(\n",
    "                                 loss=cum_loss / (i + 1), bce=cum_bce / (i + 1),\n",
    "                                 gmm=cum_gmm / LSIZE / (i + 1), mse=cum_mse / (i + 1)))\n",
    "        pbar.update(BSIZE)\n",
    "    pbar.close()\n",
    "    return cum_loss * BSIZE / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Loading MDRNN at epoch 59 with test error -1.6460504421097064\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MDRNN:\n\tsize mismatch for gmm_linear.weight: copying a param with shape torch.Size([117, 64]) from checkpoint, the shape in current model is torch.Size([117, 256]).\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([256, 21]) from checkpoint, the shape in current model is torch.Size([1024, 21]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m rnn_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(rnn_file, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading MDRNN at epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith test error \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     26\u001b[0m         rnn_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m], rnn_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m---> 27\u001b[0m mdrnn\u001b[38;5;241m.\u001b[39mload_state_dict(rnn_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(rnn_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# scheduler.load_state_dict(state['scheduler'])\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# earlystopping.load_state_dict(state['earlystopping'])\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Load only if the scheduler and early stopping states were saved with MDRNN\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MDRNN:\n\tsize mismatch for gmm_linear.weight: copying a param with shape torch.Size([117, 64]) from checkpoint, the shape in current model is torch.Size([117, 256]).\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([256, 21]) from checkpoint, the shape in current model is torch.Size([1024, 21]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024])."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # constants\n",
    "    BSIZE = 24\n",
    "    SEQ_LEN = 12\n",
    "    # epochs = 30\n",
    "\n",
    "    # Loading VAE\n",
    "    # vae, state = load_vae()\n",
    "\n",
    "    # Loading model (if it exists already)\n",
    "    rnn_dir = join(args[\"logdir\"], 'mdrnn')\n",
    "    rnn_file = join(rnn_dir, 'best.tar')\n",
    "\n",
    "    if not exists(rnn_dir):\n",
    "        mkdir(rnn_dir)\n",
    "\n",
    "    mdrnn = MDRNN(LSIZE, ASIZE, RSIZE, 5)\n",
    "    mdrnn.to(device)\n",
    "    optimizer = torch.optim.RMSprop(mdrnn.parameters(), lr=1e-3, alpha=.9)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5)\n",
    "    # earlystopping = EarlyStopping('min', patience=100)\n",
    "\n",
    "    if exists(rnn_file) and not args[\"noreload\"]:\n",
    "        rnn_state = torch.load(rnn_file)\n",
    "        print(\"Loading MDRNN at epoch {} \"\n",
    "            \"with test error {}\".format(\n",
    "                rnn_state[\"epoch\"], rnn_state[\"precision\"]))\n",
    "        mdrnn.load_state_dict(rnn_state[\"state_dict\"])\n",
    "        optimizer.load_state_dict(rnn_state[\"optimizer\"])\n",
    "\n",
    "    # Data Loading\n",
    "    dataset_test, dataset_train, test_loader, train_loader = load_data()\n",
    "    # partial() is used to create a new function train() and test() from data_pass(), one with \n",
    "    # train=True and the other with train=False\n",
    "    train = partial(data_pass, train=True, include_reward=args[\"include_reward\"])\n",
    "    test = partial(data_pass, train=False, include_reward=args[\"include_reward\"])\n",
    "\n",
    "    cur_best = None\n",
    "    train_losses = []\n",
    "\n",
    "    for e in range(args[\"epochs\"]):\n",
    "        train_loss = train(e)\n",
    "        train_losses.append(train_loss)\n",
    "        print(\"Train losses list size: \", len(train_losses))\n",
    "\n",
    "        test_loss = test(e)\n",
    "        scheduler.step(test_loss)\n",
    "        # earlystopping.step(test_loss)\n",
    "\n",
    "        is_best = not cur_best or test_loss < cur_best\n",
    "        if is_best:\n",
    "            cur_best = test_loss\n",
    "        checkpoint_fname = join(rnn_dir, 'checkpoint.tar')\n",
    "        save_checkpoint({\n",
    "            \"state_dict\": mdrnn.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            # 'earlystopping': earlystopping.state_dict(),\n",
    "            \"precision\": test_loss,\n",
    "            \"epoch\": e,\n",
    "            \"train_losses\": train_losses}, is_best, checkpoint_fname,\n",
    "                        rnn_file)\n",
    "\n",
    "        # if earlystopping.stop:\n",
    "        #     print(\"End of Training because of early stopping at epoch {}\".format(e))\n",
    "        #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
