{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.60.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard)\n",
      "  Downloading google_auth-2.26.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard)\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.24.3)\n",
      "Collecting protobuf<4.24,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (69.0.3)\n",
      "Requirement already satisfied: six>1.9 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.2.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/pedrosousa/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.26.1-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.4/186.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading grpcio-1.60.0-cp311-cp311-macosx_10_10_universal2.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: tensorboard-data-server, rsa, protobuf, oauthlib, grpcio, cachetools, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-2.0.0 cachetools-5.3.2 google-auth-2.26.1 google-auth-oauthlib-1.2.0 grpcio-1.60.0 oauthlib-3.2.2 protobuf-4.23.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Google Colab. Assuming local environment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the notebook is running on Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # This block will run only in Google Colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab. Cloning the repository.\")\n",
    "    !git clone https://github.com/pedro15sousa/R244-wm-load-balancing.git\n",
    "    %cd R244-wm-load-balancing/notebooks\n",
    "else: \n",
    "    # This block will run if not in Google Colab\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab. Assuming local environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # This adds the parent directory (main_folder) to the Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from os.path import join, exists\n",
    "from os import mkdir\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models.vae import VAE\n",
    "\n",
    "from utils.misc import save_checkpoint\n",
    "from utils.misc import LSIZE, RED_SIZE, ASIZE\n",
    "## WARNING : THIS SHOULD BE REPLACE WITH PYTORCH 0.5\n",
    "from utils.learning import EarlyStopping\n",
    "from utils.learning import ReduceLROnPlateau\n",
    "from data.loaders import RolloutObservationDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='VAE Trainer')\n",
    "# parser.add_argument('--batch-size', type=int, default=32, metavar='N',\n",
    "#                     help='input batch size for training (default: 32)')\n",
    "# parser.add_argument('--epochs', type=int, default=1000, metavar='N',\n",
    "#                     help='number of epochs to train (default: 1000)')\n",
    "# parser.add_argument('--logdir', type=str, help='Directory where results are logged')\n",
    "# parser.add_argument('--noreload', action='store_true',\n",
    "#                     help='Best model is not reloaded if specified')\n",
    "# parser.add_argument('--nosamples', action='store_true',\n",
    "#                     help='Does not save samples during training if specified')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = {\n",
    "    'batch_size': 32,   # input batch size for training (default: 32)\n",
    "    'epochs': 30,     # number of epochs to train (default: 1000)\n",
    "    'logdir': '../exp_dir',  # Directory where results are logged\n",
    "    'noreload': False,  # Set True if best model is not to be reloaded\n",
    "    'nosamples': False,  # Set True if samples are not to be saved during training\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# Fix numeric divergence due to bug in Cudnn\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "# 51 is the number of dimensions in my space: 50 servers + 1 job size\n",
    "model = VAE(ASIZE+1, LSIZE).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5)\n",
    "earlystopping = EarlyStopping('min', patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset_train = RolloutObservationDataset('../datasets/loadbalancing', train=True)\n",
    "    dataset_test = RolloutObservationDataset('../datasets/loadbalancing',train=False)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset_train, batch_size=args['batch_size'], shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=args['batch_size'], shuffle=True, num_workers=2)\n",
    "\n",
    "    return dataset_test, dataset_train, test_loader, train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logsigma):\n",
    "    \"\"\" VAE loss function \"\"\"\n",
    "    BCE = F.mse_loss(recon_x, x, size_average=False)\n",
    "    # print(mu)\n",
    "    # print(logsigma)\n",
    "    # print(recon_x)\n",
    "    # print(x)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + 2 * logsigma - mu.pow(2) - (2 * logsigma).exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \"\"\" One training epoch \"\"\"\n",
    "    model.train()\n",
    "    dataset_train.load_next_buffer()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \"\"\" One test epoch \"\"\"\n",
    "    model.eval()\n",
    "    dataset_test.load_next_buffer()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.float().to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %reload_ext tensorboard\n",
    "    %tensorboard --logdir ../exp_dir/MNIST/vae/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading file buffer ...: 100%|██████████| 200/200 \n",
      "Loading file buffer ...: 100%|██████████| 200/200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model at epoch 7, with test error 7.604264052124023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading file buffer ...: 100%|██████████| 200/200 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pedrosousa/Documents/Cambridge/Large Scale Data Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m cur_best \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, args[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     train(epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     test_loss \u001b[39m=\u001b[39m test()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# TensorBoard logging\u001b[39;00m\n",
      "\u001b[1;32m/Users/pedrosousa/Documents/Cambridge/Large Scale Data Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dataset_train\u001b[39m.\u001b[39mload_next_buffer()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Large%20Scale%20Data%20Processing/R244-wm-load-balancing/notebooks/train_vae_notebook.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_iterator()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39mstart()\n\u001b[1;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Popen(\u001b[39mself\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39mget_context()\u001b[39m.\u001b[39mProcess\u001b[39m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_launch(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39mwrite(fp\u001b[39m.\u001b[39mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the TensorBoard writer\n",
    "    logdir = args['logdir']\n",
    "    writer = SummaryWriter(os.path.join(logdir, 'vae/tensorboard'))\n",
    "\n",
    "    # load data\n",
    "    dataset_test, dataset_train, test_loader, train_loader = load_data()\n",
    "\n",
    "    # check vae dir exists, if not, create it\n",
    "    vae_dir = join(args['logdir'], 'vae')\n",
    "    if not exists(vae_dir):\n",
    "        mkdir(vae_dir)\n",
    "        mkdir(join(vae_dir, 'samples'))\n",
    "\n",
    "    reload_file = join(vae_dir, 'best.tar')\n",
    "    if not args['noreload'] and exists(reload_file):\n",
    "        state = torch.load(reload_file)\n",
    "        print(\"Reloading model at epoch {}\"\n",
    "            \", with test error {}\".format(\n",
    "                state['epoch'],\n",
    "                state['precision']))\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        scheduler.load_state_dict(state['scheduler'])\n",
    "        earlystopping.load_state_dict(state['earlystopping'])\n",
    "\n",
    "\n",
    "    cur_best = None\n",
    "\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        train(epoch)\n",
    "        test_loss = test()\n",
    "\n",
    "        # TensorBoard logging\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "\n",
    "        scheduler.step(test_loss)\n",
    "        earlystopping.step(test_loss)\n",
    "\n",
    "        # checkpointing\n",
    "        best_filename = join(vae_dir, 'best.tar')\n",
    "        filename = join(vae_dir, 'checkpoint.tar')\n",
    "        is_best = not cur_best or test_loss < cur_best\n",
    "        if is_best:\n",
    "            cur_best = test_loss\n",
    "\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'precision': test_loss,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'earlystopping': earlystopping.state_dict()\n",
    "        }, is_best, filename, best_filename)\n",
    "\n",
    "        if not args['nosamples']:\n",
    "            with torch.no_grad():\n",
    "                sample = torch.randn(RED_SIZE, LSIZE).to(device)\n",
    "                sample = model.decoder(sample).cpu()\n",
    "                save_image(sample.view(64, 3, RED_SIZE, RED_SIZE),\n",
    "                        join(vae_dir, 'samples/sample_' + str(epoch) + '.png'))\n",
    "\n",
    "        if earlystopping.stop:\n",
    "            print(\"End of Training because of early stopping at epoch {}\".format(epoch))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
